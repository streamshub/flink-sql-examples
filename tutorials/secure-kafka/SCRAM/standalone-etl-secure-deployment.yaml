apiVersion: flink.apache.org/v1beta1
kind: FlinkDeployment
metadata:
  name: standalone-etl-secure
spec:
  image: quay.io/streamshub/flink-sql-runner:main
  flinkVersion: v2_0
  flinkConfiguration:
    taskmanager.numberOfTaskSlots: "1"
  serviceAccount: flink
  podTemplate:
    kind: Pod
    spec:
      volumes:
        - name: my-cluster-cluster-ca-cert
          secret:
            secretName: my-cluster-cluster-ca-cert
            items:
              - key: ca.crt
                path: ca.crt
      containers:
        - name: flink-main-container
          volumeMounts:
            - name: my-cluster-cluster-ca-cert
              mountPath: "/opt/my-cluster-cluster-ca-cert"
              readOnly: true
          env:
            - name: USER_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-user
                  key: password
            - name: SQL_STATEMENTS
              value: |
                  CREATE TABLE SalesRecordTable (
                    invoice_id STRING,
                    user_id STRING,
                    product_id STRING,
                    quantity STRING,
                    unit_cost STRING,
                    `purchase_time` TIMESTAMP(3) METADATA FROM 'timestamp',
                    WATERMARK FOR purchase_time AS purchase_time - INTERVAL '1' SECOND
                  ) WITH (
                    'connector' = 'kafka',
                    'topic' = 'flink.sales.records',
                    'properties.bootstrap.servers' = 'my-cluster-kafka-bootstrap.flink.svc:9094',
                    'properties.security.protocol' = 'SASL_SSL',
                    'properties.ssl.truststore.location' = '/opt/my-cluster-cluster-ca-cert/ca.crt',
                    'properties.ssl.truststore.type' = 'PEM',
                    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
                    'properties.sasl.jaas.config' = 'org.apache.flink.kafka.shaded.org.apache.kafka.common.security.scram.ScramLoginModule
                      required
                        username="my-user"
                        password="$(USER_PASSWORD)"
                      \;',
                    'properties.group.id' = 'sales-record-group',
                    'value.format' = 'avro-confluent',
                    'value.avro-confluent.url' = 'http://apicurio-registry-service.flink.svc:8080/apis/ccompat/v6',
                    'scan.startup.mode' = 'latest-offset'
                  );

                  CREATE TABLE ScramAuthSalesRecordTable (
                    invoice_id STRING, 
                    user_id STRING, 
                    product_id STRING, 
                    quantity STRING, 
                    PRIMARY KEY (`user_id`) NOT ENFORCED
                  ) WITH (
                    'connector' = 'upsert-kafka', 
                    'topic' = 'flink.scram.auth.sales.records', 
                    'properties.bootstrap.servers' = 'my-cluster-kafka-bootstrap.flink.svc:9094', 
                    'properties.security.protocol' = 'SASL_SSL',
                    'properties.ssl.truststore.location' = '/opt/my-cluster-cluster-ca-cert/ca.crt',
                    'properties.ssl.truststore.type' = 'PEM',
                    'properties.sasl.mechanism' = 'SCRAM-SHA-512',
                    'properties.sasl.jaas.config' = 'org.apache.flink.kafka.shaded.org.apache.kafka.common.security.scram.ScramLoginModule
                      required
                        username="my-user"
                        password="$(USER_PASSWORD)"
                      \;',
                    'properties.client.id' = 'sql-secure-client', 
                    'properties.transaction.timeout.ms' = '800000', 
                    'key.format' = 'csv', 
                    'value.format' = 'csv', 
                    'value.fields-include' = 'ALL'
                  );

                  INSERT INTO ScramAuthSalesRecordTable 
                    SELECT 
                      invoice_id, 
                      user_id, 
                      product_id, 
                      quantity
                    FROM SalesRecordTable
                    LIMIT 10;
  jobManager:
    resource:
      memory: "2048m"
      cpu: 1
  taskManager:
    resource:
      memory: "2048m"
      cpu: 1
  job:
    jarURI: local:///opt/streamshub/flink-sql-runner.jar
    parallelism: 1
    upgradeMode: stateless
