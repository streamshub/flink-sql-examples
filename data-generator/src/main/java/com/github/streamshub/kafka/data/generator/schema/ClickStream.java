/**
 * Autogenerated by Avro
 *
 * DO NOT EDIT DIRECTLY
 */
package com.github.streamshub.kafka.data.generator.schema;

import org.apache.avro.specific.SpecificData;

@SuppressWarnings("all")
@org.apache.avro.specific.AvroGenerated
public class ClickStream extends org.apache.avro.specific.SpecificRecordBase implements org.apache.avro.specific.SpecificRecord {
  private static final long serialVersionUID = -8865219346157340073L;
  public static final org.apache.avro.Schema SCHEMA$ = new org.apache.avro.Schema.Parser().parse("{\"type\":\"record\",\"name\":\"ClickStream\",\"namespace\":\"com.github.streamshub.kafka.data.generator.schema\",\"fields\":[{\"name\":\"user_id\",\"type\":\"string\"},{\"name\":\"product_id\",\"type\":\"string\"}]}");
  public static org.apache.avro.Schema getClassSchema() { return SCHEMA$; }
  @Deprecated public CharSequence user_id;
  @Deprecated public CharSequence product_id;

  /**
   * Default constructor.  Note that this does not initialize fields
   * to their default values from the schema.  If that is desired then
   * one should use <code>newBuilder()</code>.
   */
  public ClickStream() {}

  /**
   * All-args constructor.
   * @param user_id The new value for user_id
   * @param product_id The new value for product_id
   */
  public ClickStream(CharSequence user_id, CharSequence product_id) {
    this.user_id = user_id;
    this.product_id = product_id;
  }

  public org.apache.avro.Schema getSchema() { return SCHEMA$; }
  // Used by DatumWriter.  Applications should not call.
  public Object get(int field$) {
    switch (field$) {
    case 0: return user_id;
    case 1: return product_id;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  // Used by DatumReader.  Applications should not call.
  @SuppressWarnings(value="unchecked")
  public void put(int field$, Object value$) {
    switch (field$) {
    case 0: user_id = (CharSequence)value$; break;
    case 1: product_id = (CharSequence)value$; break;
    default: throw new org.apache.avro.AvroRuntimeException("Bad index");
    }
  }

  /**
   * Gets the value of the 'user_id' field.
   * @return The value of the 'user_id' field.
   */
  public CharSequence getUserId() {
    return user_id;
  }

  /**
   * Sets the value of the 'user_id' field.
   * @param value the value to set.
   */
  public void setUserId(CharSequence value) {
    this.user_id = value;
  }

  /**
   * Gets the value of the 'product_id' field.
   * @return The value of the 'product_id' field.
   */
  public CharSequence getProductId() {
    return product_id;
  }

  /**
   * Sets the value of the 'product_id' field.
   * @param value the value to set.
   */
  public void setProductId(CharSequence value) {
    this.product_id = value;
  }

  /**
   * Creates a new ClickStream RecordBuilder.
   * @return A new ClickStream RecordBuilder
   */
  public static com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder newBuilder() {
    return new com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder();
  }

  /**
   * Creates a new ClickStream RecordBuilder by copying an existing Builder.
   * @param other The existing builder to copy.
   * @return A new ClickStream RecordBuilder
   */
  public static com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder newBuilder(com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder other) {
    return new com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder(other);
  }

  /**
   * Creates a new ClickStream RecordBuilder by copying an existing ClickStream instance.
   * @param other The existing instance to copy.
   * @return A new ClickStream RecordBuilder
   */
  public static com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder newBuilder(com.github.streamshub.kafka.data.generator.schema.ClickStream other) {
    return new com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder(other);
  }

  /**
   * RecordBuilder for ClickStream instances.
   */
  public static class Builder extends org.apache.avro.specific.SpecificRecordBuilderBase<ClickStream>
    implements org.apache.avro.data.RecordBuilder<ClickStream> {

    private CharSequence user_id;
    private CharSequence product_id;

    /** Creates a new Builder */
    private Builder() {
      super(SCHEMA$);
    }

    /**
     * Creates a Builder by copying an existing Builder.
     * @param other The existing Builder to copy.
     */
    private Builder(com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder other) {
      super(other);
      if (isValidValue(fields()[0], other.user_id)) {
        this.user_id = data().deepCopy(fields()[0].schema(), other.user_id);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.product_id)) {
        this.product_id = data().deepCopy(fields()[1].schema(), other.product_id);
        fieldSetFlags()[1] = true;
      }
    }

    /**
     * Creates a Builder by copying an existing ClickStream instance
     * @param other The existing instance to copy.
     */
    private Builder(com.github.streamshub.kafka.data.generator.schema.ClickStream other) {
            super(SCHEMA$);
      if (isValidValue(fields()[0], other.user_id)) {
        this.user_id = data().deepCopy(fields()[0].schema(), other.user_id);
        fieldSetFlags()[0] = true;
      }
      if (isValidValue(fields()[1], other.product_id)) {
        this.product_id = data().deepCopy(fields()[1].schema(), other.product_id);
        fieldSetFlags()[1] = true;
      }
    }

    /**
      * Gets the value of the 'user_id' field.
      * @return The value.
      */
    public CharSequence getUserId() {
      return user_id;
    }

    /**
      * Sets the value of the 'user_id' field.
      * @param value The value of 'user_id'.
      * @return This builder.
      */
    public com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder setUserId(CharSequence value) {
      validate(fields()[0], value);
      this.user_id = value;
      fieldSetFlags()[0] = true;
      return this;
    }

    /**
      * Checks whether the 'user_id' field has been set.
      * @return True if the 'user_id' field has been set, false otherwise.
      */
    public boolean hasUserId() {
      return fieldSetFlags()[0];
    }


    /**
      * Clears the value of the 'user_id' field.
      * @return This builder.
      */
    public com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder clearUserId() {
      user_id = null;
      fieldSetFlags()[0] = false;
      return this;
    }

    /**
      * Gets the value of the 'product_id' field.
      * @return The value.
      */
    public CharSequence getProductId() {
      return product_id;
    }

    /**
      * Sets the value of the 'product_id' field.
      * @param value The value of 'product_id'.
      * @return This builder.
      */
    public com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder setProductId(CharSequence value) {
      validate(fields()[1], value);
      this.product_id = value;
      fieldSetFlags()[1] = true;
      return this;
    }

    /**
      * Checks whether the 'product_id' field has been set.
      * @return True if the 'product_id' field has been set, false otherwise.
      */
    public boolean hasProductId() {
      return fieldSetFlags()[1];
    }


    /**
      * Clears the value of the 'product_id' field.
      * @return This builder.
      */
    public com.github.streamshub.kafka.data.generator.schema.ClickStream.Builder clearProductId() {
      product_id = null;
      fieldSetFlags()[1] = false;
      return this;
    }

    @Override
    public ClickStream build() {
      try {
        ClickStream record = new ClickStream();
        record.user_id = fieldSetFlags()[0] ? this.user_id : (CharSequence) defaultValue(fields()[0]);
        record.product_id = fieldSetFlags()[1] ? this.product_id : (CharSequence) defaultValue(fields()[1]);
        return record;
      } catch (Exception e) {
        throw new org.apache.avro.AvroRuntimeException(e);
      }
    }
  }

  private static final org.apache.avro.io.DatumWriter
    WRITER$ = new org.apache.avro.specific.SpecificDatumWriter(SCHEMA$);

  @Override public void writeExternal(java.io.ObjectOutput out)
    throws java.io.IOException {
    WRITER$.write(this, SpecificData.getEncoder(out));
  }

  private static final org.apache.avro.io.DatumReader
    READER$ = new org.apache.avro.specific.SpecificDatumReader(SCHEMA$);

  @Override public void readExternal(java.io.ObjectInput in)
    throws java.io.IOException {
    READER$.read(this, SpecificData.getDecoder(in));
  }

}
